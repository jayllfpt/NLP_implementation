{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPE tokenization\n",
    "text = \"students play soccer cat is playing with students\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word list: ['soccer', 'play', 'students', 'playing', 'is', 'with', 'cat']\n"
     ]
    }
   ],
   "source": [
    "wordList = list(set(text.split()))\n",
    "print(f'word list: {wordList}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init corpus: {'students': 2, 'play': 1, 'soccer': 1, 'cat': 1, 'is': 1, 'playing': 1, 'with': 1}\n",
      "init splits: {'soccer': ['s', 'o', 'c', 'c', 'e', 'r'], 'play': ['p', 'l', 'a', 'y'], 'students': ['s', 't', 'u', 'd', 'e', 'n', 't', 's'], 'playing': ['p', 'l', 'a', 'y', 'i', 'n', 'g'], 'is': ['i', 's'], 'with': ['w', 'i', 't', 'h'], 'cat': ['c', 'a', 't']}\n",
      "init vocab: {'g', 'y', 'c', 'd', 'n', 'i', 'l', 'a', 't', 'o', 'e', 'u', 'h', 's', 'r'}\n"
     ]
    }
   ],
   "source": [
    "corpus = {}\n",
    "for word in text.split():\n",
    "    cleaned_word = word.strip('.,!?').lower()\n",
    "    if cleaned_word in corpus:\n",
    "        corpus[cleaned_word] += 1\n",
    "    else:\n",
    "        corpus[cleaned_word] = 1\n",
    "print(f'init corpus: {corpus}')\n",
    "\n",
    "splits = {}\n",
    "vocab = set() \n",
    "for word in wordList:\n",
    "    _split = [word[0]]\n",
    "    for i in range(1, len(word)):\n",
    "        _split.append(word[i])\n",
    "        vocab.add(word[i])\n",
    "    splits[word] = _split\n",
    "print(f'init splits: {splits}')\n",
    "print(f'init vocab: {vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added: pl with freq: 2\n",
      "added: pla with freq: 2\n",
      "added: play with freq: 2\n",
      "added: so with freq: 1\n",
      "added: soc with freq: 1\n"
     ]
    }
   ],
   "source": [
    "# training phase\n",
    "train_iter = 20\n",
    "merge_rule = set()\n",
    "while len(vocab) < train_iter:\n",
    "    dic = {}\n",
    "    top_key1, top_key2, top_val, _merge = '','', 0, ''\n",
    "\n",
    "    # find the pair with highest frequency\n",
    "    for split in splits.values():\n",
    "        # add merges\n",
    "        for index in range(0, len(split) - 1):\n",
    "            pair = split[index] + split[index+1]\n",
    "            if pair in dic:\n",
    "                dic[pair] += 1\n",
    "            else:\n",
    "                dic[pair] = 1\n",
    "            if dic[pair] > top_val:\n",
    "                top_val = dic[pair] # highest frequency\n",
    "                top_key1 = split[index] # first tok\n",
    "                top_key2 = split[index + 1] # second tok\n",
    "                _merge = top_key1 + '+' + top_key2 # add merge rules\n",
    "\n",
    "    merge_rule.add(_merge)\n",
    "    vocab.add(top_key1+top_key2)\n",
    "    print(f'added: {top_key1}{top_key2} with freq: {top_val}')\n",
    "\n",
    "    # update splits\n",
    "    for w, split in splits.items():\n",
    "        _split = []\n",
    "        index = 0\n",
    "        while index < len(split) - 1:\n",
    "            if split[index] == top_key1 and split[index+1] == top_key2:\n",
    "                _split.append(top_key1+top_key2)\n",
    "                index += 2\n",
    "            else:\n",
    "                _split.append(split[index])\n",
    "                index += 1\n",
    "        _split.append(split[-1])\n",
    "        splits[w] = _split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated vocab: {'pl', 'n', 'l', 'a', 't', 'r', 'g', 'play', 'pla', 'o', 'e', 'u', 'y', 'c', 'soc', 's', 'so', 'd', 'i', 'h'}\n",
      "merge rules: ['so+c', 's+o', 'pla+y', 'pl+a', 'p+l']\n"
     ]
    }
   ],
   "source": [
    "merge_rule = sorted(merge_rule, reverse=True)\n",
    "print(f'updated vocab: {vocab}')\n",
    "print(f'merge rules: {merge_rule}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pl', 'a', 'y', 'e', 'd']\n"
     ]
    }
   ],
   "source": [
    "text2 = 'played'\n",
    "tokens = [ch for ch in text2]\n",
    "\n",
    "for rule in merge_rule:\n",
    "    keys = rule.split('+')\n",
    "    index = 0\n",
    "    _tokens = []\n",
    "    while index < len(tokens) - 1:\n",
    "        if tokens[index] == keys[0] and tokens[index+1] == keys[1]:\n",
    "            _tokens.append(keys[0]+keys[1])\n",
    "            index += 2\n",
    "        else:\n",
    "            _tokens.append(tokens[index])\n",
    "            index += 1\n",
    "    _tokens.append(tokens[-1])\n",
    "    tokens = _tokens\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
