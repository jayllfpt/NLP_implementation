{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Sample documents\n",
    "documents = ['cat is cute', 'dog ask questions', 'cat does not ask questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Tokenization and document frequency (DF) calculation\n",
    "def tokenize(document):\n",
    "    return document.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ask', 'cat', 'cute', 'does', 'dog', 'is', 'not', 'questions'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a set of unique terms in the corpus\n",
    "corpus = set()\n",
    "document_frequency = {}\n",
    "for document in documents:\n",
    "    tokens = tokenize(document)\n",
    "    for token in tokens:\n",
    "        if token not in corpus:\n",
    "            corpus.add(token)\n",
    "        if token not in document_frequency:\n",
    "            document_frequency[token] = 1\n",
    "        else:\n",
    "            document_frequency[token] += 1\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Term frequency (TF) calculation\n",
    "def calculate_tf(document):\n",
    "    tokens = tokenize(document)\n",
    "    tf = {}\n",
    "    for token in tokens:\n",
    "        if token not in tf:\n",
    "            tf[token] = 1\n",
    "        else:\n",
    "            tf[token] += 1\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Inverse Document Frequency (IDF) calculation\n",
    "def calculate_idf(token):\n",
    "    if token in document_frequency:\n",
    "        return math.log(len(documents) / document_frequency[token] + 1)\n",
    "    else:\n",
    "        return 0  # Token not found in any document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cat': 0.9162907318741551,\n",
       "  'is': 1.3862943611198906,\n",
       "  'cute': 1.3862943611198906},\n",
       " {'dog': 1.3862943611198906,\n",
       "  'ask': 0.9162907318741551,\n",
       "  'questions': 0.9162907318741551},\n",
       " {'cat': 0.9162907318741551,\n",
       "  'does': 1.3862943611198906,\n",
       "  'not': 1.3862943611198906,\n",
       "  'ask': 0.9162907318741551,\n",
       "  'questions': 0.9162907318741551}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Calculate TF-IDF scores\n",
    "tfidf_scores = []\n",
    "for document in documents:\n",
    "    tf = calculate_tf(document)\n",
    "    tfidf = {}\n",
    "    for token in tf:\n",
    "        tfidf[token] = tf[token] * calculate_idf(token)\n",
    "    tfidf_scores.append(tfidf)\n",
    "    \n",
    "tfidf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 TF-IDF Scores:\n",
      "cat: 0.9162907318741551\n",
      "is: 1.3862943611198906\n",
      "cute: 1.3862943611198906\n",
      "\n",
      "\n",
      "Document 2 TF-IDF Scores:\n",
      "dog: 1.3862943611198906\n",
      "ask: 0.9162907318741551\n",
      "questions: 0.9162907318741551\n",
      "\n",
      "\n",
      "Document 3 TF-IDF Scores:\n",
      "cat: 0.9162907318741551\n",
      "does: 1.3862943611198906\n",
      "not: 1.3862943611198906\n",
      "ask: 0.9162907318741551\n",
      "questions: 0.9162907318741551\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print TF-IDF scores for each document\n",
    "for i, tfidf in enumerate(tfidf_scores):\n",
    "    print(f\"Document {i+1} TF-IDF Scores:\")\n",
    "    for token, score in tfidf.items():\n",
    "        print(f\"{token}: {score}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
